\documentclass{article}
\usepackage{arxiv}

\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{doi}

\usepackage[warn]{mathtext}
\usepackage[utf8]{inputenc}  
\usepackage{indentfirst}
\usepackage{csquotes}

\usepackage[bibstyle=gost-numeric, sorting=none]{biblatex}
\addbibresource{references.bib}

% math
\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools,esint,eucal}


\title{Автоматическая аннотация тем в вероятностном тематическом моделировании}

\author{ Карпинская Анна Викторовна\\
	Московский государственный университет имени М. В. Ломоносова \\
        Научный руководитель: Воронцов Константин Вячеславович \\
 \texttt{annakarpinckaya@gmail.com} \\
	%% examples of more authors
	%% \AND
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
	%% \And
	%% Coauthor \\
	%% Affiliation \\
	%% Address \\
	%% \texttt{email} \\
}
\date{}

\renewcommand{\shorttitle}{\textit{arXiv} Template}

%%% Add PDF metadata to help others organize their library
%%% Once the PDF is generated, you can check the metadata with
%%% $ pdfinfo template.pdf
\hypersetup{
pdftitle={A template for the arxiv style},
pdfsubject={q-bio.NC, q-bio.QM},
pdfauthor={David S.~Hippocampus, Elias D.~Striatum},
pdfkeywords={First keyword, Second keyword, More},
}

\begin{document}
\maketitle

\begin{abstract}
	Вероятностное тематическое моделирование широко используется для выявления скрытых тем в текстах, что делает его важным инструментом для анализа больших текстовых корпусов. Задача именования тем подразумевают понимание смысла этих тем и создание понятных названий для каждой из них. В данной работе рассматриваются методы автоматического именования и суммаризации тем, выделенных в процессе вероятностного тематического моделирования. Приводятся подходы, основанные на оценке релевантности слов для тем, а также методы генерации кратких описаний для облегчения их интерпретации. Проводится анализ эффективности предложенных методов на текстовых корпусах разной тематики, что подтверждает их значимость для применения результатов тематического моделирования.
\end{abstract}


\keywords{Тематическое моделирование \and Автоматическая аннотация \and Суммаризация текста \and Генеративные модели \and Метрики качества текста \and Вероятностные модели \and LDA \and T5 \and NLP \and Семантическая близость}


\section{Введение}
Современные технологии обработки текста и анализа данных способствовали развитию вероятностного тематического моделирования, которое используется для выявления скрытых тем в больших текстовых коллекциях. \cite{blei2011introduction} Это направление нашло широкое применение в задачах анализа документов, информационного поиска и построения автоматических рекомендаций. Однако использование результатов тематического моделирования ограничивается сложностью их интерпретации, так как модели часто предоставляют лишь наборы ключевых слов, которые не всегда позволяют понять суть выявленных тем. \cite{perez2020interpretable}

Для решения этой проблемы активно исследуются методы автоматической аннотации и суммаризации тем. Такие подходы позволяют создавать понятные текстовые описания, которые упрощают интерпретацию и применение результатов моделирования. Одним из ключевых направлений является интеграция вероятностных моделей с генеративными языковыми моделями, которые обеспечивают связность и читаемость итоговых текстов.

Особенно актуальной задачей является адаптация систем аннотации к коллекциям документов разной тематики и объема. Например, использование современных моделей, таких как T5 и GPT, в сочетании с тематическими моделями, позволяет формировать краткие описания тем на основе ключевых фраз и репрезентативных фрагментов текста. Эти методы способны не только повышать точность, но и улучшать восприятие результатов тематического анализа. \cite{lau2011automatic}

В данной статье предлагается методика, которая объединяет вероятностное тематическое моделирование, методы извлечения ключевых фраз и генеративные модели. Представленные подходы направлены на повышение связности и релевантности генерируемых текстов. Для оценки эффективности подхода используются стандартные метрики, такие как ROUGE, BLEU и METEOR, а также косинусное сходство векторных представлений текстов. Экспериментальная часть включает тестирование на реальных данных, что позволяет оценить общее качество генерируемых аннотаций.

\section{Постановка задачи}

Задача автоматической аннотации и суммаризации тем в текстовых коллекциях представляет собой задачу генерации кратких и содержательных описаний для набора документов, объединённых в темы. \cite{langston2024automated} В данном исследовании тексты новостных статей из набора данных BBC News используются для создания таких описаний.

В данном случае тексты статей представляют собой документированные данные, разбитые по темам. 

Множество документов $ \mathcal{D} = \{D_1, D_2, \ldots, D_N\} $, где каждый документ $ D_i $ описан текстом $ T(D_i) $.

Множество тем $ \mathcal{T} = \{T_1, T_2, \ldots, T_K\} $, где каждая тема $ T_k $ содержит подмножество документов $ \mathcal{D}_k \subseteq \mathcal{D} $.

Каждая тема содержит набор статей, которые необходимо обработать для извлечения репрезентативных фрагментов и ключевых фраз. \cite{5langston2024automated} На основе этих данных требуется сгенерировать связное описание, которое бы отражало основное содержание темы.

\vspace{12pt}
Выходные данные:
Для каждой темы $ T_k $ необходимо создать описание $ S_k $, которое удовлетворяет следующим критериям:

\begin{itemize}
    \item Является связным текстом.
    \item Содержит ключевые аспекты документов, входящих в $ \mathcal{D}_k $.
    \item Является кратким, но информативным.
\end{itemize}


Задача:
\begin{itemize}
    \item Извлечь репрезентативные фрагменты из текстов документов $ \mathcal{D}_k $, чтобы охарактеризовать основное содержание темы.
    \item Формирование набор ключевых фраз, отражающих основные концепты темы.
    \item Генерация связное описание $ S_k $, используя комбинацию репрезентативных фрагментов и ключевых фраз с помощью генеративной модели (например, T5).
\end{itemize}

Таким образом, итоговая задача сводится к построению функции $ G(T_k) $, которая для темы $ T_k $ из множества документов $ \mathcal{D}_k $ создаёт текст $ S_k $:
$$
G(T_k) = S_k, \quad \text{где } S_k = \text{генерируемое описание темы}.
$$

\section{Описание алгоритма}

Для автоматической аннотации и суммаризации тем в текстах используется алгоритм, который включает в себя три основных этапа: 
\begin{itemize}
    \item Отбор репрезентативных фрагментов
    \item Извлечение ключевых фраз
    \item Генерация текстовых описаний
\end{itemize} 
Каждый этап реализуется с применением современных языковых моделей и методов тематического моделирования. В качестве основы используются вероятностное тематическое моделирование и генеративные модели, такие как T5.\cite{6ronnqvist2015exploratory}

\subsection{Извлечение репрезентативных фрагментов}

На первом этапе документы, входящие в одну тему, объединяются в общий текст. Для каждого предложения в объединённом тексте рассчитывается оценка релевантности теме, основанная на частотности ключевых токенов. Репрезентативные фрагменты определяются как предложения с наивысшими значениями релевантности:
\begin{itemize}
    \item Все тексты проходят лемматизацию и удаление стоп-слов для формирования множества токенов.
    \item Для каждого предложения вычисляется его релевантность как сумма частот ключевых токенов, встречающихся в нём.
    \item Выбираются $ N_{\text{top}} $ предложений с максимальными значениями релевантности.
\end{itemize}

\subsection{Извлечение ключевых фраз}

Для извлечения ключевых фраз используются современные модели эмбеддингов, такие как Sentence-BERT \cite{7kiselev2005clustering}:
\begin{itemize}
    \item Кандидатные ключевые фразы извлекаются из объединённого текста с использованием методов выделения именных групп.
    \item Для каждого документа и ключевой фразы вычисляется эмбеддинг. Центроидный вектор темы формируется как среднее значение векторов всех документов.
    \item Косинусное сходство между векторами ключевых фраз и центроидным вектором темы используется для выбора наиболее релевантных ключевых фраз.
\end{itemize}

\subsection{Генерация описаний}

Используя репрезентативные фрагменты и ключевые фразы, формируется входной промпт для генеративной модели:
\begin{itemize}
    \item Входные данные включают список ключевых фраз и репрезентативных предложений.
    \item Генеративная модель (в данном случае T5) генерирует текстовое описание темы, основываясь на предоставленном промпте.\cite{8daume2009alignment}
\end{itemize}

\subsection{Оценка качества}

Для оценки качества генерируемых описаний используются метрики, которые измеряют релевантность, связность и полноту текстов. Основные используемые метрики:

ROUGE — измеряет пересечение n-грамм между сгенерированным текстом и эталоном:
  $$
  P = \frac{\text{Совпадающие } n\text{-граммы}}{\text{Общее количество } n\text{-грамм в предсказании}}
  $$
  $$
  \quad R = \frac{\text{Совпадающие } n\text{-граммы}}{\text{Общее количество } n\text{-грамм в эталоне}}
  $$
  $$
  \quad F_1 = \frac{2PR}{P + R}
  $$

BLEU — использует n-граммную точность, взвешенную с учётом штрафа за длину:
  $$
  \text{BLEU} = \text{BP} \cdot \exp \left( \sum_{n=1}^N w_n \log P_n \right)
  $$

METEOR — учитывает лемматизацию, синонимы и порядок слов:
  $$
  \text{METEOR} = 10 \cdot \frac{\text{Совпадения}}{\text{Средняя длина текста}}
  $$

Семантическая близость — вычисляется через косинусное сходство между эмбеддингами сгенерированного текста и эталона:
  $$
  \text{Sim}(u, v) = \frac{u \cdot v}{\|u\| \|v\|}
  $$

Эти метрики позволяют объективно оценить качество аннотации и выявить сильные и слабые стороны алгоритма.

\section{Эксперименты}

\subsection{Описание данных}

Для экспериментов использовались данные из открытого набора BBC News Data, который включает текстовые данные пяти категорий: \textbf{business}, \textbf{entertainment}, \textbf{politics}, \textbf{sport} и \textbf{tech}. Каждый документ представляет собой новостную статью, сгруппированную по теме.

Для каждой категории предоставлены наборы текстов, которые позволяют провести тематическое моделирование и автоматическую аннотацию.

В Tаблице \ref{fig:table} ниже представлено распределение данных по категориям:

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|}
\hline
Категория & Количество документов & Пример содержания\\
\hline
Business  & 510  & Экономика, финансы, корпоративные новости \\
 Entertainment & 386 & Кино, музыка, шоу-бизнес \\
 Politics & 417  & Политические события, выборы  \\
 Sport & 511  & Новости спорта, результаты матчей \\
 Tech & 401 & Технологические разработки, гаджеты   \\
\hline
\end{tabular}
\caption{Статистика категорий корпуса данных}
\label{fig:table}
\end{table}

\subsection{Предварительно обученные модели NLP}

Для реализации алгоритма аннотации и суммаризации тем использовались предварительно обученные языковые модели, способные эффективно обрабатывать текст на английском языке. Эти модели обучены на больших корпусах данных и способны извлекать как контекстуальные, так и семантические зависимости между словами.

В данном исследовании основное внимание уделяется применению модели T5 (Text-to-Text Transfer Transformer) для генерации описаний тем. \cite{vaswani2017attention} T5 адаптирована для задач как суммаризации текста, так и обработки контекстных данных.

\subsection{Архитектура модели T5}

Модель T5 представляет собой мощную архитектуру Transformer, которая переводит задачи NLP в единую текстовую форму. На этапе экспериментов использовалась версия модели, предварительно обученная на корпусе C4 (Colossal Clean Crawled Corpus). \cite{5langston2024automated} Эта архитектура позволяет:
\begin{itemize}
    \item Генерировать связные описания тем.
    \item Учитывать широкий контекст текстовых данных.
    \item Эффективно адаптироваться к задачам аннотации.
\end{itemize}
\subsection{Обоснование выбора модели}

Для данного исследования T5 была выбрана по следующим причинам:
\begin{enumerate}
    \item Гибкость: модель способна адаптироваться к различным задачам, включая тематическую суммаризацию и генерацию текстов.
    \item Качество генерации текста: демонстрирует высокие показатели на эталонных наборах данных для задач суммаризации.
    \item Поддержка сложных структур: позволяет учитывать как длинные, так и короткие текстовые контексты.
\end{enumerate}

Для получения эмбеддингов, используемых в оценке семантической близости, применялись Sentence-BERT и Universal Sentence Encoder. Эти модели помогают оценить качество сгенерированных текстов по отношению к исходным.

\subsection{Методы оценки}

Для оценки качества аннотаций и суммаризации тем использовались следующие метрики \cite{papineni2002bleu}:
\begin{itemize}
    \item ROUGE: для измерения пересечения n-грамм между сгенерированным текстом и эталоном.
    \item BLEU: для оценки точности генерации на уровне n-грамм.
    \item METEOR: учитывает синонимы, порядок слов и точность в тексте.
    \item Семантическая близость: косинусное сходство эмбеддингов текста.
\end{itemize}


 \begin{figure}[!htb]
    \centering
    \includegraphics[width=0.8\textwidth]{metrics_ngramm.pdf}
    \caption{Сравнение метрик BLEU, METEOR и Semantic Similarity}
    \label{fig:1}
\end{figure}

По результатам анализа на Рис.\ref{fig:1} можно заметить, что семантическая близость демонстрирует значительно более высокие значения по сравнению с метриками BLEU и METEOR. Это указывает на способность алгоритма улавливать контекст и создавать описания, которые близки по смыслу к исходным данным, даже при наличии отклонений в синтаксической структуре. С другой стороны, BLEU-метрика показывает низкие значения для всех категорий, что говорит о различиях между сгенерированными описаниями и эталонами в последовательности слов и точном совпадении n-грамм. Модель создает более вариативные и свободные описания, которые не всегда точно соответствуют тексту эталона.


 \begin{figure}[!htb]
    \centering
    \includegraphics[width=0.8\textwidth]{metrics_rouge.pdf}
    \caption{Сравнение ROUGE-метрик}
    \label{fig:2}
\end{figure}


На Рис.\ref{fig:2} видно, что ROUGE-1 метрика демонстрирует наивысшие значения для категорий politics и tech, что свидетельствует о хорошей способности модели передавать ключевые слова и выражения из исходных текстов. Однако ROUGE-2 метрика показывает значительно более низкие значения по сравнению с ROUGE-1, что говорит о том, что модель имеет затруднения с передачей более длинных последовательностей слов.


\section{Заключение}

Задача автоматической аннотации и суммаризации тем была формализована как задача генерации краткого и связного текста, который описывает основное содержание документов, принадлежащих к одной теме. 

В рамках исследования использовался подход, основанный на вероятностном тематическом моделировании и генеративных моделях, таких как T5, для формирования текстовых описаний. Для оценки качества сгенерированных текстов применялись стандартные метрики: ROUGE, BLEU, METEOR и семантическая близость. Эти метрики позволили получить представление о соответствии сгенерированных текстов исходным данным.

Результаты экспериментов показали, что метрика семантической близости демонстрирует наиболее высокие значения по сравнению с BLEU и METEOR. Это свидетельствует о способности модели учитывать контекст текста и создавать описания, соответствующие исходному содержанию. 

ROUGE-метрики варьируются в зависимости от категории текста, что показывает различия в сложности генерации кратких описаний для каждой темы. Например, наилучшие результаты наблюдаются для категорий politics и tech, что может быть связано с высокой структурированностью данных в этих категориях.

Обзор литературных источников и результаты экспериментов подтверждают, что использование современных моделей, таких как T5, в сочетании с методами оценки качества, основанными на семантической близости, позволяет значительно улучшить результаты автоматической аннотации. 

\bibliographystyle{unsrtnat}
\printbibliography

\end{document}
